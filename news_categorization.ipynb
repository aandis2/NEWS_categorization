{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\n\n# Load the dataset\ndf = pd.read_json('/kaggle/input/news-category-dataset/News_Category_Dataset_v3.json', lines=True)\n\n# Displaying the first few rows of the dataset\nprint(df.head())\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-08-12T17:27:45.984649Z","iopub.execute_input":"2023-08-12T17:27:45.985003Z","iopub.status.idle":"2023-08-12T17:27:49.474263Z","shell.execute_reply.started":"2023-08-12T17:27:45.984975Z","shell.execute_reply":"2023-08-12T17:27:49.473261Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom wordcloud import WordCloud\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\n\n# Data Exploration\nprint(\"Dataset structure:\")\nprint(df.info())\n\nprint(\"Missing values:\")\nprint(df.isnull().sum())\n\nprint(\"Unique categories:\")\nprint(df['category'].unique())\n\nprint(\"Descriptive statistics:\")\nprint(df.describe())\n\n# Preprocessing\n# Handle missing values\ndf = df.dropna(subset=['headline', 'short_description'])\n\n# Remove duplicates\ndf = df.drop_duplicates()\n\n# Text Analysis and Feature Extraction\n# Tokenization\ndf['headline_tokens'] = df['headline'].apply(word_tokenize)\ndf['description_tokens'] = df['short_description'].apply(word_tokenize)\n\n# Remove stopwords\nstop_words = set(stopwords.words('english'))\ndf['headline_tokens'] = df['headline_tokens'].apply(lambda tokens: [word for word in tokens if word.lower() not in stop_words])\ndf['description_tokens'] = df['description_tokens'].apply(lambda tokens: [word for word in tokens if word.lower() not in stop_words])\n\n","metadata":{"execution":{"iopub.status.busy":"2023-08-12T17:27:49.475956Z","iopub.execute_input":"2023-08-12T17:27:49.476815Z","iopub.status.idle":"2023-08-12T17:28:55.836118Z","shell.execute_reply.started":"2023-08-12T17:27:49.476783Z","shell.execute_reply":"2023-08-12T17:28:55.834345Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Data Visualization\n# Category distribution\nplt.figure(figsize=(10, 6))\nsns.countplot(y='category', data=df)\nplt.title('Category Distribution')\nplt.xlabel('Count')\nplt.ylabel('Category')\nplt.show()\n\n# Word cloud of headline words\nheadline_words = ' '.join(df['headline'].str.lower())\nwordcloud = WordCloud(width=800, height=400, background_color='white').generate(headline_words)\nplt.figure(figsize=(10, 6))\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis('off')\nplt.title('Word Cloud - Headline Words')\nplt.show()\n\n\n","metadata":{"execution":{"iopub.status.busy":"2023-08-12T17:28:55.837962Z","iopub.execute_input":"2023-08-12T17:28:55.838377Z","iopub.status.idle":"2023-08-12T17:29:07.655238Z","shell.execute_reply.started":"2023-08-12T17:28:55.838347Z","shell.execute_reply":"2023-08-12T17:29:07.654231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Word cloud of description words\ndescription_words = ' '.join(df['short_description'].str.lower())\nwordcloud = WordCloud(width=800, height=400, background_color='white').generate(description_words)\nplt.figure(figsize=(10, 6))\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis('off')\nplt.title('Word Cloud - Description Words')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-08-12T17:29:07.657104Z","iopub.execute_input":"2023-08-12T17:29:07.658056Z","iopub.status.idle":"2023-08-12T17:29:23.596290Z","shell.execute_reply.started":"2023-08-12T17:29:07.658003Z","shell.execute_reply":"2023-08-12T17:29:23.594977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report, confusion_matrix\n\n\n# Preprocessing\ndf = df.dropna(subset=['headline', 'short_description'])\n\n# Convert token lists to strings\ndf['headline_tokens'] = df['headline_tokens'].apply(' '.join)\ndf['description_tokens'] = df['description_tokens'].apply(' '.join)\n\n# Combine headline and short description into a single text feature\ndf['text'] = df['headline_tokens'] + ' ' + df['description_tokens']\n\n# Drop duplicates\ndf = df.drop_duplicates(subset='text')\n\n\n# Feature Engineering\n# Combine headline and short description into a single text feature\ndf['text'] = df['headline'] + ' ' + df['short_description']\n\n# Split the dataset into train and test sets\nX_train, X_test, y_train, y_test = train_test_split(df['text'], df['category'], test_size=0.2, random_state=42)\n\n# Feature Extraction\nvectorizer = TfidfVectorizer()\nX_train_vectorized = vectorizer.fit_transform(X_train)\nX_test_vectorized = vectorizer.transform(X_test)\n\n","metadata":{"execution":{"iopub.status.busy":"2023-08-12T17:33:22.782698Z","iopub.execute_input":"2023-08-12T17:33:22.783054Z","iopub.status.idle":"2023-08-12T17:33:29.384145Z","shell.execute_reply.started":"2023-08-12T17:33:22.783027Z","shell.execute_reply":"2023-08-12T17:33:29.383340Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Modeling - Logistic Regression\nmodel = LogisticRegression()\nmodel.fit(X_train_vectorized, y_train)\n\n","metadata":{"execution":{"iopub.status.busy":"2023-08-12T17:33:34.720374Z","iopub.execute_input":"2023-08-12T17:33:34.720947Z","iopub.status.idle":"2023-08-12T17:35:28.820367Z","shell.execute_reply.started":"2023-08-12T17:33:34.720914Z","shell.execute_reply":"2023-08-12T17:35:28.819671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluation\ny_pred = model.predict(X_test_vectorized)\nprint('Classification Report:')\nprint(classification_report(y_test, y_pred))\n\nprint('Confusion Matrix:')\nprint(confusion_matrix(y_test, y_pred))\n","metadata":{"execution":{"iopub.status.busy":"2023-08-12T17:35:47.968101Z","iopub.execute_input":"2023-08-12T17:35:47.968468Z","iopub.status.idle":"2023-08-12T17:35:50.063607Z","shell.execute_reply.started":"2023-08-12T17:35:47.968436Z","shell.execute_reply":"2023-08-12T17:35:50.062205Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Interpretation\n# Get the most important features (words) for each category\nfeature_names = vectorizer.get_feature_names_out()\ncategories = df['category'].unique()\n\nfor category in categories:\n    category_index = model.classes_.tolist().index(category)\n    top_features = model.coef_[category_index].argsort()[-10:][::-1]\n    top_words = [feature_names[idx] for idx in top_features]\n    print(f'Top words for category \"{category}\":')\n    print(top_words)\n    print()","metadata":{"execution":{"iopub.status.busy":"2023-08-12T17:35:56.090377Z","iopub.execute_input":"2023-08-12T17:35:56.090746Z","iopub.status.idle":"2023-08-12T17:35:56.555168Z","shell.execute_reply.started":"2023-08-12T17:35:56.090714Z","shell.execute_reply":"2023-08-12T17:35:56.554179Z"},"trusted":true},"execution_count":null,"outputs":[]}]}